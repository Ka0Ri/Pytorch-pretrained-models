{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\neptune\\common\\warnings.py:62: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import Modules.model.Segment as Segment\n",
    "import torch\n",
    "import Modules.model.Detector as Detector\n",
    "import Modules.model.Classifier as Classifier\n",
    "import os\n",
    "from torchvision.transforms._presets import ObjectDetection\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from Modules.dataloader import base_dataset, DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PennFudanDataset(base_dataset):\n",
    "\n",
    "    def __init__(self, transform=None,\n",
    "                 data_path='../../data/PennFudanPed/'):\n",
    "        \n",
    "        \n",
    "        imgs = list(map(lambda img: os.path.join(data_path, \"PNGImages\", img), \n",
    "                        sorted(os.listdir(os.path.join(data_path, \"PNGImages\")))))\n",
    "        masks = list(map(lambda mask: os.path.join(data_path, \"PedMasks\", mask), \n",
    "                        sorted(os.listdir(os.path.join(data_path, \"PedMasks\")))))\n",
    "        \n",
    "        if(transform is None):\n",
    "            transform = partial(ObjectDetection)()\n",
    "\n",
    "        super(PennFudanDataset, self).__init__(data=imgs, targets=masks, transform=transform)\n",
    "\n",
    "    def __parse_mask__(self, mask):\n",
    "        mask = np.array(mask)\n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.nonzero(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        return boxes, masks, obj_ids\n",
    "\n",
    "    def __load_sample__(self, index) -> dict:\n",
    "        \n",
    "        img = Image.open(self.data[index]).convert(\"RGB\")\n",
    "        mask = Image.open(self.targets[index]).convert('L')\n",
    "        boxes, masks, obj_ids = self.__parse_mask__(mask)\n",
    "\n",
    "        return {'data': img,\n",
    "                'target': {'boxes': boxes,\n",
    "                           'masks': masks,\n",
    "                           'obj_ids': obj_ids},\n",
    "                'original': img}\n",
    "    \n",
    "    def __transform__(self, sample: dict) -> dict:\n",
    "        \n",
    "        boxes = sample['target']['boxes']\n",
    "        masks = sample['target']['masks']\n",
    "        num_objs = len(sample['target']['obj_ids'])\n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        # image_id = torch.tensor([index])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = torch.tensor([0])\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        sample.update({'target': target})\n",
    "\n",
    "        return super().__transform__(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PennFudanDataset(data_path='data\\PennFudanPed', \n",
    "                           transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [tensor([[[0.1294, 0.1373, 0.1216,  ..., 0.4314, 0.4314, 0.4196],\n",
      "         [0.1412, 0.1608, 0.1608,  ..., 0.3608, 0.3804, 0.3725],\n",
      "         [0.1373, 0.1569, 0.1569,  ..., 0.3020, 0.3137, 0.3216],\n",
      "         ...,\n",
      "         [0.7882, 0.7843, 0.7804,  ..., 0.7137, 0.7137, 0.7176],\n",
      "         [0.7922, 0.7804, 0.7765,  ..., 0.7176, 0.7176, 0.7176],\n",
      "         [0.7961, 0.7843, 0.7725,  ..., 0.7098, 0.7098, 0.7098]],\n",
      "\n",
      "        [[0.1647, 0.1725, 0.1569,  ..., 0.3725, 0.3725, 0.3608],\n",
      "         [0.1765, 0.1961, 0.1961,  ..., 0.3137, 0.3216, 0.3255],\n",
      "         [0.1725, 0.1922, 0.1922,  ..., 0.2588, 0.2667, 0.2784],\n",
      "         ...,\n",
      "         [0.7843, 0.7804, 0.7765,  ..., 0.6980, 0.6980, 0.7020],\n",
      "         [0.7882, 0.7765, 0.7725,  ..., 0.7020, 0.7020, 0.7020],\n",
      "         [0.7922, 0.7804, 0.7686,  ..., 0.6941, 0.6941, 0.6941]],\n",
      "\n",
      "        [[0.1451, 0.1529, 0.1373,  ..., 0.3843, 0.3843, 0.3725],\n",
      "         [0.1647, 0.1765, 0.1843,  ..., 0.3216, 0.3333, 0.3333],\n",
      "         [0.1686, 0.1804, 0.1882,  ..., 0.2745, 0.2824, 0.2941],\n",
      "         ...,\n",
      "         [0.7686, 0.7647, 0.7608,  ..., 0.6863, 0.6863, 0.6902],\n",
      "         [0.7725, 0.7608, 0.7569,  ..., 0.6902, 0.6902, 0.6902],\n",
      "         [0.7765, 0.7647, 0.7529,  ..., 0.6824, 0.6824, 0.6824]]]), tensor([[[0.2235, 0.2196, 0.2039,  ..., 0.1529, 0.1608, 0.2667],\n",
      "         [0.2196, 0.2157, 0.2039,  ..., 0.2078, 0.2235, 0.2588],\n",
      "         [0.2196, 0.2157, 0.2078,  ..., 0.2275, 0.2471, 0.2157],\n",
      "         ...,\n",
      "         [0.2157, 0.2078, 0.1961,  ..., 0.6745, 0.6667, 0.7020],\n",
      "         [0.2000, 0.2000, 0.2000,  ..., 0.7176, 0.7059, 0.7294],\n",
      "         [0.1961, 0.2039, 0.2118,  ..., 0.7647, 0.7451, 0.7412]],\n",
      "\n",
      "        [[0.2431, 0.2392, 0.2353,  ..., 0.2471, 0.2471, 0.3529],\n",
      "         [0.2392, 0.2353, 0.2353,  ..., 0.2980, 0.3098, 0.3451],\n",
      "         [0.2392, 0.2353, 0.2392,  ..., 0.3255, 0.3412, 0.3059],\n",
      "         ...,\n",
      "         [0.3765, 0.3686, 0.3569,  ..., 0.8549, 0.8431, 0.8824],\n",
      "         [0.3569, 0.3569, 0.3569,  ..., 0.8941, 0.8824, 0.9059],\n",
      "         [0.3529, 0.3608, 0.3686,  ..., 0.9412, 0.9216, 0.9176]],\n",
      "\n",
      "        [[0.1647, 0.1608, 0.1529,  ..., 0.1216, 0.1569, 0.2706],\n",
      "         [0.1608, 0.1569, 0.1529,  ..., 0.1843, 0.2196, 0.2627],\n",
      "         [0.1608, 0.1569, 0.1569,  ..., 0.2118, 0.2471, 0.2275],\n",
      "         ...,\n",
      "         [0.1569, 0.1490, 0.1373,  ..., 0.3765, 0.3765, 0.4039],\n",
      "         [0.1490, 0.1490, 0.1490,  ..., 0.4275, 0.4235, 0.4392],\n",
      "         [0.1490, 0.1569, 0.1647,  ..., 0.4824, 0.4627, 0.4588]]])], 'target': [{'boxes': tensor([[ 42.,  21., 127., 316.]]), 'labels': tensor([1]), 'masks': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8), 'image_id': tensor([0]), 'area': tensor([25075.]), 'iscrowd': tensor([0])}, {'boxes': tensor([[106.,  59., 274., 362.]]), 'labels': tensor([1]), 'masks': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8), 'image_id': tensor([0]), 'area': tensor([50904.]), 'iscrowd': tensor([0])}], 'original': [<PIL.Image.Image image mode=RGB size=324x334 at 0x1181768BD90>, <PIL.Image.Image image mode=RGB size=536x382 at 0x1181768BDC0>]}\n"
     ]
    }
   ],
   "source": [
    "from Modules.dataloader import collate_fn_dict\n",
    "\n",
    "data_loader = DataModule(dataset, \n",
    "                        batch_size=2,\n",
    "                        num_workers=0,\n",
    "                        collate_fn=collate_fn_dict)\n",
    "\n",
    "data_loader.setup(stage = \"fit\")\n",
    "\n",
    "for batch in data_loader.train_dataloader():\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from typing import List\n",
    "\n",
    "def get_optimizer(parameters: List, settings: dict) -> optim.Optimizer:\n",
    "    \"\"\"\n",
    "    Set up learning optimizer\n",
    "    Args:\n",
    "        parameters: model's parameters\n",
    "        settings: settings hyperparameters\n",
    "    Returns:\n",
    "        optimizer: optimizer\n",
    "    \"\"\"\n",
    "    optimizer_mapping = {\n",
    "        'adam': lambda: optim.Adam(parameters, lr=settings['lr'], weight_decay=settings['weight_decay']),\n",
    "        'sgd': lambda: optim.SGD(parameters, lr=settings['lr'], weight_decay=settings['weight_decay'], momentum=settings['momentum']),\n",
    "    }\n",
    "\n",
    "    optimizer_creator = optimizer_mapping.get(settings['optimizer'])\n",
    "\n",
    "    if optimizer_creator is not None:\n",
    "        return optimizer_creator()\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "# Example usage:\n",
    "model_parameters = [torch.nn.Parameter(torch.randn(20, 20, requires_grad=True))]\n",
    "optimizer_settings = {'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 0.0001}\n",
    "optimizer_instance = get_optimizer(model_parameters, optimizer_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max\n"
     ]
    }
   ],
   "source": [
    "metric_modes = {'acc': 'max', 'dice': 'max', 'mAP': 'max'}\n",
    "mode = metric_modes.get('acc', 'min')\n",
    "print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\neptune\\common\\warnings.py:62: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Modules.ultis import get_basic_callbacks\n",
    "\n",
    "callbacks = get_basic_callbacks(metric_name='acc',\n",
    "                                ckpt_path='checkpoints',\n",
    "                                early_stopping=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.ultis import get_trainer\n",
    "\n",
    "trainer = get_trainer(logger=True,\n",
    "                      gpu_ids=[0],\n",
    "                      n_gpu=1,\n",
    "                      metric_name='acc',\n",
    "                      ckpt_path='checkpoints',\n",
    "                      early_stopping=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AISeed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
